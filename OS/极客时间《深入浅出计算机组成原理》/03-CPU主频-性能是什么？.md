# 通过你的CPU主频，我们来谈谈“性能”究竟是什么？

## 1 性能——时间的倒数

衡量计算机性能主要有两个指标：

- **响应时间**（Response time）或者叫**执行时间**（Execution time）。提升这个指标，就是就是让计算机更快的执行指令。
- **吞吐率**（Throughput）或者**带宽**（Bandwidth），提升这个指标，就是让计算机在单位时间内做更多的事。

响应时间指的就是，执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好。吞吐率是指我们在一定的时间范围内能处理的数据或者执行的程序指令。

**提升吞吐率的办法**：

- 一般来说，缩短响应时间，响应的吞吐量也会提高。相对困难， 因为 CPU 的性能提升其实在 10 年前就处于“挤牙膏”的状态了。
- 增加 cpu 数量，相对简单。

**性能——时间的倒数**：

- 我们一般把性能，定义成响应时间的倒数，也就是：`性能 = 1/ 响应时间`。

响应时间越短，性能的数值就越大。

**SPEC**：

各大 CPU 和服务器厂商组织了一个叫作SPEC（Standard Performance Evaluation Corporation）的第三方机构，专门用来指定各种“跑分”的规则。具体参考[All SPEC CPU2017 Results Published by SPEC](https://www.spec.org/cpu2017/results/cpu2017.html)。

## 2 计算机的计时单位：CPU 时钟

时间是一个很自然的用来衡量性能的指标，但是用时间来衡量有两个问题。

### 问题 1：时间不“准”

我们可能这样去测试程序执行所花费的时间，但得到的结果并非该程序所消耗的 CPU 时间。而且每一次统计结果不会完全一样。有可能这一次花了 45ms，下一次变成了 53ms。

```java
public static void main(String[] args){
    long start = System.currenttimemillis();
    //... do something
    System.out.print(System.currenttimemillis()-start)
}
```

不准的主要原因是：

1. 首先，我们统计时间是用类似于“掐秒表”一样，记录程序运行结束的时间减去程序开始运行的时间。这个时间也叫 Wall Clock Time 或者 Elapsed Time，就是在运行程序期间，挂在墙上的钟走掉的时间。
2. 但是，计算机可能同时运行着好多个程序，CPU 实际上不停地在各个程序之间进行切换。在这些走掉的时间里面，很可能 CPU 切换去运行别的程序了。而且，有些程序在运行的时候，可能要从网络、硬盘去读取数据，要等网络和硬盘把数据读出来，给到内存和 CPU。所以要想准确统计某个程序运行时间，进而去比较两个程序的实际性能，我们得把这些时间给刨除掉。

#### time 命令

Linux 下有一个叫 time 的命令，可以帮我们统计出来，同样的 Wall Clock Time 下，程序实际在 CPU 上到底花了多少时间。

```shell
$ time seq 1000000 | wc -l
1000000

real  0m0.101s
user  0m0.031s
sys   0m0.016s
```

time 命令。它会返回三个值：

- real time，也就是我们说的 Wall Clock Time。
- user time，也就是 CPU 在运行你的程序时，在用户态运行指令的时间；
- sys time，是 CPU 在运行你的程序，在操作系统内核里运行指令的时间。

>注意，如果在一台多核或者多cpu的机器上运行，seq 和 wc 命令可能会分配到两个 cpu 上，user 和 sys 是两个 cpu 时间相加的，而 real只是现实时钟里走过的时间，user+sys 可能大于 real，极端情况下 user+sys 可以到达 real 的两倍。

**程序实际花费的 CPU 执行时间（CPU Time）= `user time + sys time`**。

根据上面输出，程序真正消耗的 CPU 时间是 `0.031+0.016 = 0.047s`，剩余的 `0.054s` 其实是 CPU 在作其他的事。

### 问题 2：即使我们已经拿到了 CPU 时间，我们也不一定可以直接“比较”出两个程序的性能差异

原因在于：

- 即使在同一台计算机上，CPU 可能满载运行也可能降频运行，降频运行的时候自然花的时间会多一些
- 除了 CPU 之外，时间这个性能指标还会受到主板、内存这些其他相关硬件的影响。

基于此，我们需要对时间进行拆解——把程序的 CPU 执行时间变成 **CPU 时钟周期数（CPU Cycles）** 和 **时钟周期时间（Clock Cycle）**的乘积。

```log
    程序的 CPU 执行时间 = CPU 时钟周期数×时钟周期时间
```

#### 时钟周期时间

什么是时钟周期时间，以 CPU 的一个重要参数主频来说明，比如 `Intel Core-i7-7700HQ 2.8GHz`，这里的 2.8GHz 就是电脑的主频（Frequency/Clock Rate）。这个 2.8GHz，可以先粗浅地认为，**CPU 在 1 秒时间内，可以执行的简单指令的数量是 2.8G 条**。

>赫兹（符号：Hz）是频率的国际单位制单位，表示每一秒周期性事件发生的次数。

根据频率公式我们可以得出，上面 CPU 的时钟周期时间是 `1/2.8G`，即 `1/2.8G` 是该 CPU 能够识别出来的最小的时间间隔。就像墙上的挂钟能够识别出来的最小时间单位就是秒一样。

>CPU 内部，和我们平时戴的电子石英表类似，有一个叫晶体振荡器（Oscillator Crystal）的东西，简称为晶振。我们把晶振当成 CPU 内部的电子表来使用。晶振带来的每一次“滴答”，就是时钟周期时间。

因此，CPU 主频越高，意味着 CPU 的跑得越快。相应的如果希望得到更好的性能，可以更换主频更改的 CPU，然后这是硬件层面的东西，对于我们程序员来讲这是不可同的，特别是客户端程序员。按照公式 `程序的 CPU 执行时间 = CPU 时钟周期数 × 时钟周期时间`，可以看出，想要提升性能，除了减少时钟周期时间，还可以 **减少程序的 CPU 时钟周期数**，而这是我们程序员可以做到的。

#### CPU 时钟周期数

**并不是每条指令都对应一个 CPU 时钟周期，复制指令可能需要多个 CPU 时钟周期才能完成**，因此对于程序的 CPU 时钟周期数，可以进一步分解为：`指令数 × 每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）`。即 `程序的 CPU 执行时间 = 指令数 × CPI× Clock Cycle Time`。

因此，如果我们想要解决性能问题，其实就是要优化这三者：

- 时钟周期时间，就是计算机主频，这个取决于计算机硬件。
- 每条指令的平均时钟周期数 CPI，就是一条指令到底需要多少 CPU Cycle。
- 指令数，代表执行我们的程序到底需要多少条指令、用哪些指令。这个很多时候就把挑战交给了编译器。同样的代码，编译成计算机指令时候，就有各种不同的表示方式。

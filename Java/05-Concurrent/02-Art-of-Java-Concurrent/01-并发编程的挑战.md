# 编程编程的挑战

---
## 1 上下文切换

首先我们知道，即使是单核的 cpu 也支持多线程的程序，cpu 通过不停的给每个线程分配**时间片**来实现这个机制，这个时间片就是 cpu 分配给各个线程的执行时间，由于这个时间片非常的短，所以我们感觉好像就是多个线程在同时执行一样，一般时间片长为**几十毫秒**。

当执行完一个时间片后需要切换到下一个任务，在切换之前 cpu 需要**保持现在这个线程的状态**，然后再去执行下一个线程，当 cpu 再次切换到原来的线程时，需要先**读取之前的任务的一个状态**，然后再继续执行，这样从**保存到再加载**就是一个上下文切换的过程。

---
### 多线程一定快么

上下文的切换是需要开销的，所以并不见得多线程就比单个线程快，而是应该根据具体的任务与硬件的配置来控制多线程的数量。线程过多可能造成CPU利用率达到100%。

参考下面程序，通过改变 count 值来检测单线程和多线下的执行效率：

```java
public class ConcurrencyTest {

    /** 执行次数 */
    private static final long count = 10000l;

    public static void main(String[] args) throws InterruptedException {
        //并发计算
        concurrency();
        //单线程计算
        serial();
    }

    private static void concurrency() throws InterruptedException {
        long start = System.currentTimeMillis();
        Thread thread = new Thread(new Runnable() {
            @Override
            public void run() {
                int a = 0;
                for (long i = 0; i < count; i++) {
                    a += 5;
                }
                System.out.println(a);
            }
        });
        thread.start();
        int b = 0;
        for (long i = 0; i < count; i++) {
            b--;
        }
        thread.join();
        long time = System.currentTimeMillis() - start;
        System.out.println("concurrency :" + time + "ms,b=" + b);
    }

    private static void serial() {
        long start = System.currentTimeMillis();
        int a = 0;
        for (long i = 0; i < count; i++) {
            a += 5;
        }
        int b = 0;
        for (long i = 0; i < count; i++) {
            b--;
        }
        long time = System.currentTimeMillis() - start;
        System.out.println("serial:" + time + "ms,b=" + b + ",a=" + a);
    }

}
```

执行结果：

```
100000
concurrency :16ms,b=-10000
serial:0ms,b=-10000,a=50000

10000000
concurrency :16ms,b=-10000000
serial:31ms,b=-10000000,a=50000000
```

根据不同的 count 值，我们可以得出结论：当并发执行累加操作不超过**百万次时**，速度会比串行执行累加操作要慢。那么，为什么并发执行的速度会比串行慢呢？这是因为**线程有创建和上下文切换的开销**。


---
### 测试上下文切换次数和时长

- 使用 Lmbench3 可以测量上下文切换的时长。
- 使用 vmstat 可以测量上下文切换的次数。

---
### 如何减少上下文切换

如果能够减少上下文切换必然能提高程序的运行效率。

- **无锁并发编程**：多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。
- **CAS算法**：Java的Atomic包使用CAS算法来更新数据，而不需要加锁。
- **合理使用线程**：避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。
- **协程**：协程表示一个方法具有多个入口，在单线程里维持多个任务的切换

CAS(（compare and swap)):对竞争资源不用加锁，而是假设没有冲突去完成某项操作，如果因为冲突失败就不断重试，直到成功为止。以此来减少上下文切换。上面所说的循环CAS操作就是上面所说的乐观锁。

---
### 减少上下文切实战

通过相关工具获取线程等待信息，然后根据信息调整线程数量和调度策略。

```
# 使用 jps 命令查看当前运行的java线程
# 使用 jstack java_pid 目录 dump 线程信息
# 使用 greap 目录可以过滤一些关键信息
```

---
## 2 死锁

锁是个非常有用的工具，运用场景非常多，因为它使用起来非常简单，而且易于理解。但同时它也会带来一些困扰，那就是可能会引起死锁，一旦产生死锁，就会造成系统功能不可用。参选下面代码：

```java
public class DeadLockDemo {

    /** A锁 */
    private static String A = "A";
    /** B锁 */
    private static String B = "B";

    public static void main(String[] args) {
        new DeadLockDemo().deadLock();
    }

    private void deadLock() {
        Thread t1 = new Thread(new Runnable() {
            @Override
            public void run() {
                synchronized (A) {
                    try {
                        Thread.sleep(2000);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    synchronized (B) {
                        System.out.println("1");
                    }
                }
            }
        });

        Thread t2 = new Thread(new Runnable() {
            @Override
            public void run() {
                synchronized (B) {
                    synchronized (A) {
                        System.out.println("2");
                    }
                }
            }
        });
        t1.start();
        t2.start();
    }

}
```

运行上面程序会产生死锁，可以使用下面步骤进行分析：

```
λ jps #获取 java 进程 id
9652 Launcher
13016 RemoteMavenServer
10844 DeadLockDemo
11356
7276 Jps

jstack 10844 # 获取对应进程的线程信息

"Thread-1" #12 prio=5 os_prio=0 tid=0x000000001929a800 nid=0x34d8 waiting for monitor entry [0x0000000019d7f000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at chapter01.DeadLockDemo$2.run(DeadLockDemo.java:42)
        - waiting to lock <0x00000000d614d2a0> (a java.lang.String)
        - locked <0x00000000d614d2d0> (a java.lang.String)
        at java.lang.Thread.run(Thread.java:745)

"Thread-0" #11 prio=5 os_prio=0 tid=0x0000000019298000 nid=0x183c waiting for monitor entry [0x0000000019c7f000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at chapter01.DeadLockDemo$1.run(DeadLockDemo.java:31)
        - waiting to lock <0x00000000d614d2d0> (a java.lang.String)
        - locked <0x00000000d614d2a0> (a java.lang.String)
        at java.lang.Thread.run(Thread.java:745)
```

避免死锁的几个常见方法：

- 避免一个线程同时获取多个锁。
- 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
- 尝试使用定时锁，使用 JUC `lock.tryLock(timeout)`来替代使用内部锁机制。
- 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。


---
## 3 资源限制的挑战

### 什么是资源限制

资源限制是指：在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源，比如服务器带宽只有2Mb/s，某个资源的下载速度是1Mb/s，系统启动10个线程下载资源，下载速度不会变成10Mb/s.

硬件资源限制有：

- 带宽的上传和下载速度
- 硬盘读写速度，I/O 瓶颈
- cpu处理速度，CPU计算瓶颈

软件资源限制有：

- 数据库的连接数
- socket的连接数

### 资源限制引发的问题

并发编程中，将代码的执行速度加快的原则是将代码中串行执行部分变成并行的，但是如果将某段串行执行的代码变成并行之后，因为资源的限制，仍然在串行执行，那么这个时候程序的执行速度并没有加快执行，反而更慢。因为增加了上下文切换和资源调度的时间。

### 如何解决资源限制

- 对于硬件资源限制，考虑使用集群并行执行程序。既然单机的资源有限制
- 对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket连接复用，或者在调用对方webservice接口获取数据时，只建立一个连接。

### 在资源限制下如何进行并发编程

如何在资源限制的情况下，让程序执行得更快呢？方法就是，根据不同的资源限制调整程序的并发度。

比如：下载文件程序依赖于两个资源：带宽和硬盘读写速度。有数据库操作时，涉及数据库连接数，如果SQL语句执行非常快，而线程的数量比数据库连接数大很多，则某些线程会被阻塞，等待数据库连接。




